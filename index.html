<!--doctype html-->
<html lang="en">
<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-168892872-2"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-168892872-2');
	</script>
	
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="Vicente Ordonez, 2020">
  <title>Vicente Ordonez's Homepage</title>

  <link href="css/bootstrap.min.css" rel="stylesheet">
  <link href="css/style.css" rel="stylesheet">

  <link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <link rel="icon" href="images/vislang-emoji.png" sizes="64x64" type="image/png">
  <meta name="theme-color" content="#563d7c">
</head>

<body>

<div class="container blank-container">

	<header class="website-header">    
		<div class="d-flex flex-column flex-md-row align-items-center mb-3 border-bottom px-0 px-md-3 pt-4 pb-3">
      <div class="website-header-box text-left mr-auto d-none d-md-block">
        <a href="https://www.vislang.ai" class="plain">
        <div class="vislang-head-text">
            <img src="images/vislang-logo.png" class="group-logo" alt="Vision, Language and Learning Lab"/>
          </div>
          <div class="institution-head-text">
              <div class="divider-bar">|</div> <span class="uva-color">University of Virginia</span>
        </div>
          </a>
      </div>

      <div class="website-header-box text-left d-block d-md-none my-2 pb-1">
          <a href="https://www.vislang.ai" class="plain">
          <div class="vislang-head-text">
              <img src="images/vislang-logo.png"  class="group-logo-small" alt="Vision, Language and Learning Lab"/>
          </div> 
          <div class="institution-head-text">
              <div class="divider-bar">|</div> <span class="uva-color">UVA</span>
          </div>
          </a>
      </div>

		    <div class="nav-scroller">
		    <nav class="nav d-flex justify-content-end">

		      <a class="px-2 text-dark m-0" href="https://www.vislang.ai">home</a>
		      <a class="px-2 text-dark m-0" href="https://www.vislang.ai/people">people</a>
		      <a class="px-2 text-dark m-0" href="https://www.vislang.ai/demos">demos</a>
		      <a class="px-2 text-dark m-0" href="https://www.vislang.ai/publications">publications</a>
		    </nav>
		    </div>
		</div>
	</header>

	<div class="container mb-0">
    <div class="row">

 		<div class="px-1 px-md-4 py-3 col-lg-12">

	     	<div class="subtext">

		      	<img src="images/vicente-v03-small.jpg" style="height:215px;" class="float-left mr-3 mb-3 img-thumbnail img-fluid" alt="Vicente Ordonez">

            <div class="x-badge mb-3" style="line-height: 1.2em;">
            <h3 id="name" class="p-0 m-0 mb-1">Vicente Ord&oacute;&ntilde;ez Rom&aacute;n</h3> 
            <div>
              <div>Assistant Professor <span style="color:#888"></span></div>
              <div>Department of Computer Science</div>
              <div><a href="http://www.virginia.edu">University of Virginia</a></div>
              <div style="font-size:0.95em">vicente@virginia.edu</div>
            </div>
            </div>
            
            <div class="mt-5 mt-sm-3">
              <p class="subtext">My research lies at the intersection of Computer Vision, Natural Language Processing and Machine Learning. I am especially interested
              in analyzing, and mining useful human insights from enormous amounts of images with associated text to improve visual recognition.
              I am also interested in building efficient visual recognition models that can perform high-level perceptual tasks for applications
              in social media, urban computing, and everyday activities. More recently, I am also involved in research on fairness and accountability in machine learning applications.
              </p>

              <p class="subtext m-0">I'm a tenure-track Assistant Professor in the Department of Computer Science at the University of Virginia where I lead the <a href="https://www.vislang.ai" style="font-weight:bold">Vision, Language, and Learning lab</a>. I have also spent time as visiting professor at <a href="https://research.adobe.com/">Adobe Research</a> and as visiting researcher at the <a href="http://allenai.org">Allen Institute for Artificial Intelligence (AI2)</a>. I received my PhD in Computer Science at the <a href="http://www.unc.edu">University of North Carolina at Chapel Hill</a> in 2015 advised by Prof. <a href="http://tamaraberg.com">Tamara Berg</a>.
              Previously, I obtained an MS in Computer Science at <a href="http://www.stonybrook.edu">Stony Brook University (SUNY)</a> and an engineering degree at the <a href="http://www.espol.edu.ec">Escuela Superior Polit&eacute;cnica del Litoral</a> in Ecuador.
              I'm a recipient of a Best -Long- Paper Award at the 2017 Conference on Empirical Methods in Natural Language Processing (<a href="http://emnlp2017.net/">EMNLP</a>), and the Best Paper -<a href="http://www.pamitc.org/iccv13/awards.php">Marr Prize</a>- Award at the 2013 International Conference in Computer Vision (ICCV). I have also been awarded an IBM Faculty Award, a Google Faculty Research Award, and a Facebook Research Award. Here is a link to an official <a href="bio.txt">bio</a>, and my <a href="cv_vicente.pdf">curriculum vitae</a>.
              </p>
            </div>
	      </div>
    </div>


  	</div>
	</div>

	<div class="row">

	    <div class="col-md-6">

	      <div class="row no-gutters flex-md-row mb-2 position-relative">
	      	
	        <div class="col px-4 py-3 pb-2 d-flex flex-column position-static">
	          <strong class="d-inline-block mb-0">News and Updates</strong>
				<ul class="p-2 m-0 ml-2 text-smaller">
					
					<li>06/2020. Andrew Ng's deeplearning.ai has a blog post highlighting our ACL 2020 paper Double-Hard Debias [<a href="https://blog.deeplearning.ai/blog/the-batch-nlp-special-issue-powerful-techniques-from-amazon-apple-facebook-google-microsoft-salesforce">link</a>].</li>
					<li>05/2020. With a group of colleagues we released our white paper <a href="https://www.ajlunited.org/federal-office-call">Face Recognition Technologies in the Wild: A Call for a Federal Office</a>.</li>
					<li>05/2020. Received a <a href="https://research.fb.com/blog/2020/05/announcing-the-winners-of-the-towards-on-device-ai-research-awards/">Facebook AI Research Award</a>.</li>
					<li>08/2020. Co-Organizing the <a href="https://dramaqa.snu.ac.kr/Workshop/2020">The 2nd workshop on Video Turing Test:
Toward Human-Level Video Story Understanding</a> at ECCV 2020.</li>
					<li>Serving as Area Chair for <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>, <a href="https://eccv2020.eu/">ECCV 2020</a>, <a href="https://acl2020.org/">ACL 2020</a>.</li>
					<li>10/2019. Invited Speaker at ICCV 2019 <a href="https://sites.google.com/view/lingir">Workshop on Linguistics Meets Image and Video Retrieval</a>. Seoul, South Korea.</li>
					<li> Posts from NVIDIA [<a href="https://news.developer.nvidia.com/ai-model-can-generate-images-from-natural-language-descriptions/">link</a>] and IBM Research [<a href="https://www.ibm.com/blogs/research/2019/06/text2scene-textual-descriptions/">link</a>] about <a href="https://arxiv.org/abs/1809.01110">Text2Scene</a></li>
					<li>06/2019. <a href="https://arxiv.org/abs/1809.01110">Text2Scene</a> gets named among 45 Best CVPR Paper Finalists among 1,294 accepted papers (top 1% of all submissions) [<a href="http://cvpr2019.thecvf.com/files/CVPR%202019%20-%20Welcome%20Slides%20Final.pdf">link</a>]</li>
					<!--li>05/2019. Invited Panelist at Ethics in AI Panel at <a href="https://escapevelocity.events/">Escape Velocity 2019</a>, Washington DC's National Harbor.</li-->
					<!--li>04/2019. PhD Student <a href="http://www.cs.virginia.edu/~tw8cb">Tianlu Wang</a> speaking at the <a href="https://tomtomfest.com/machine-learning/amlc-speakers/">TomTom Applied Machine Learning Conference</a>.</li>
					<li>09/2018. Panelist and co-organizer. <a href="http://tapiaconference.org/schedule/friday-september-21-2018/1030am-1200pm/dealing-with-bias-and-unfairness-in-machine-learning-algorithms/"> Dealing with Bias and Unfairness in ML</a> at ACM Richard Tapia Celebration of Diversity in Computing, Orlando, FL.</li-->
				    <!--li>09/2018. Invited Speaker, <a href="https://sites.google.com/view/sivl/">ECCV Workshop on Shortcomings in Vision and Language (SiVL)</a>, Munich, Germany.</li-->
					<!--li>03/2018. Keynote Speaker, <a href="http://ivl.ut.ee/index.php/Main/Programme">Integrating Vision and Language (iV&amp;L)</a> Conference, Tartu, Estonia.</li-->
					<!--li>02/2018. Received a <a href="https://research.googleblog.com/2018/03/google-faculty-research-awards-2017.html">Google Faculty Research Award 2017</a>. Thanks Google!</li>
					<li>01/2018. Received an <a href="https://www.research.ibm.com/university/awards/faculty_innovation_2017.shtml">IBM Faculty Award 2017</a>. Thanks IBM!</li-->
					<!--li>Quoted in The Cavalier Daily [<a href="http://www.cavalierdaily.com/article/2017/09/apples-face-id-recognizing-a-promising-future">1</a>] [<a href="http://www.cavalierdaily.com/article/2017/10/audio-manipulation-technology-has-the-potential-for-creating-fake-news">2</a>] and WIRED [<a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/">3</a>].</li-->
					<!--li>08/2017. Our work at UVA with UCLA's NLP Group gets coverage in <a href="https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/">WIRED</a>, <a href="http://www.dailymail.co.uk/sciencetech/article-4810982/AIs-learn-photos-sexist.html">Daily Mail</a>, <a href="https://www.thetimes.co.uk/article/home-robots-will-turn-into-crude-sexists-experts-warn-gnmj09rgq">The Times of London</a>, <a href="https://www.glamour.com/story/even-artificial-intelligence-is-sexist">Glamour</a>, <a href="https://www.bloomberg.com/news/articles/2017-12-04/researchers-combat-gender-and-racial-bias-in-artificial-intelligence">Bloomberg</a>.</li-->
					<!--li>09/2017. Best --Long-- Paper Award at <a href="http://emnlp2017.net/">EMNLP 2017</a>~!</li-->
					<!--li>2 long papers accepted to EMNLP 2017, 1 paper accepted to CVPR 2017</li-->
				    <!--li>10/30/2016. Our work at the Allen Institute on accelerating neural networks gets featured in the <a href="http://www.nytimes.com/2016/10/31/technology/beyond-silicon-squeezing-more-out-of-chips.html">New York Times</a> and <a href="https://news.cs.washington.edu/2016/10/31/uw-cse-and-ai2-in-the-new-york-times-artificial-intelligence-at-your-fingertips/">UW CSE News</a>.</li-->
					<!--li>October 14th, 2016 - Presented at the <a href="https://pages.shanti.virginia.edu/DHUVA_Conference_9-16/schedule-registration/">DH@UVA Digital Humanities Conference</a>, and our group also got featured in <a href="https://www.news.virginia.edu/content/powerful-legacy-and-bright-future-digital-humanities">UVA Today</a> in a related note.</li>
					<li>Oct. 14th, 2016 - Our group's research gets a mention in <a href="https://www.news.virginia.edu/content/powerful-legacy-and-bright-future-digital-humanities">UVA Today</a>.</li>
					<li>July 1st, 2016 - Organized the <a href="http://www.cs.virginia.edu/~vicente/bigvision2016">BigVision</a> workshop at CVPR 2016.</li>
					<li>Advice to prospective graduate students interested in our group [<a href="note.html">here</a>]</li-->
				</ul>
	        </div>

	      </div>

	    </div>

	    <div class="col-md-6">

	      <div class="row no-gutters flex-md-row mb-2 position-relative">
	      	
	        <div class="col px-4 py-3 pb-2 d-flex flex-column position-static">
	          <strong class="d-inline-block mb-0">Teaching</strong>
		        <ul class="text-smaller p-2 m-0 ml-2">
		        	<li>Vision &amp; Language [<a href="http://vicenteordonez.com/vislang">Fall 2020</a>]</li>
		        	<li>Deep Learning for Visual Recognition [<a href="http://vicenteordonez.com/deeplearning">Spring 2020</a>] [<a href="http://vicenteordonez.com/deeplearning/2019">Spring 2019</a>]</li>
					<li>Introduction to Computer Vision [<a href="http://vicenteordonez.com/vision/">Fall 2019</a>] [<a href="http://vicenteordonez.com/vision/2018">Spring 2018</a>]</li>
					<li>Computational Visual Recognition [<a href="http://www.cs.virginia.edu/~vicente/recognition/">Fall 2017</a>] [<a href="http://www.cs.virginia.edu/~vicente/recognition/2016">Fall 2016</a>]</li>
					<li>Vision &amp; Language [<a href="http://www.cs.virginia.edu/~vicente/vislang/">Spring 2017</a>]</li>
				</ul>
				<div class="subtext">I'm also co-organizing with students in my group the <a href="http://vision.cs.virginia.edu/seminar">UVA Computer Vision seminar</a>. I also co-direct with Paul Humphreys the <a href="http://hmi.virginia.edu">Human and Machine Intelligence seminar</a>.</div>
		        </div>
	      </div>

	    </div>

	 </div>

</div>

<main role="main" class="container blank-container">
  <div class="row mx-0 mx-lg-2">
    <div class="col-md-8 website-main">

    	<div class="blog-post subtext px-2 pt-2 pb-0">
        <ul class="list-unstyled">
          <li class="media">
            <a href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1145952bc185203f3d009_FRTsFederalOfficeMay2020.pdf">
            	<img class="mr-3 rounded-lg" src="images/frts-image.png" width="96" alt="">
            </a>
            <div class="media-body">
              <p class="my-auto">
              <a class="blue_link" href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1145952bc185203f3d009_FRTsFederalOfficeMay2020.pdf">Facial Recognition Technologies in the Wild: A Call for a Federal Office</a> <br/>
              <span class="pub_authors">Erik Learned-Miller, Vicente Ord&oacute;&ntilde;ez, Jamie Morgenstern, Joy Buolamwini.</span>
              <div class="text-muted font-italic">
               This whitepaper makes the case for a federal office in charge of regulating Face Recognition Technologies (FRTs). 
               We argue that benchmarks are insufficient for determining the appropriateness for FRTs and a more holstic approach
               is needed that takes into account technical, societal and legal challenges.
          	  </div>
          	  May 29th 2020. <a href="https://www.ajlunited.org/federal-office-call">https://www.ajlunited.org/federal-office-call</a>
              </p>
            </div>
          </li>

          <li class="media">
            <a class="blue_link" href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1002058516c11edc66a14_FRTsPrimerMay2020.pdf">
            <img class="mr-3 rounded-lg" src="images/frts-primer.png" width="96" alt="">
        	</a>
            <div class="media-body">
              <p class="my-auto">
              <a class="blue_link" href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1002058516c11edc66a14_FRTsPrimerMay2020.pdf">Facial Recognition Technologies: A Primer</a> <br/>
              <span class="pub_authors">Joy Buolamwini, Vicente Ord&oacute;&ntilde;ez, Jamie Morgenstern, Erik Learned-Miller.</span>
              <div class="text-muted font-italic">
               This is a companion to our whitepaper on "Facial Recognition Technologies in the Wild: A Call for a Federal Office" that introduces
               terminology and concepts underlying Facial Recognition Technologies (FRTs) to a broader audience.
          	  </div>
          	  May 29th 2020. <a href="https://www.ajlunited.org/federal-office-call">https://www.ajlunited.org/federal-office-call</a>
              </p>
            </div>
          </li>
      	</ul>
  	 	</div>

 	<h3 class="pb-0 mb-4">
        Preprints
  </h3>

    <div class="blog-post subtext p-2">
        <ul class="list-unstyled">

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/drise.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/2006.03204">
                Black-box Explanation of Object Detectors via Saliency Maps
              </a> <br/>
              <span class="pub_authors">
                Vitali Petsiuk, Rajiv Jain, Varun Manjunatha, Vlad I. Morariu, Ashutosh Mehra, Vicente Ordonez, Kate Saenko.
              </span><br/>
              <span class="pub_info">
                arxiv:2006.03204. June 2020.
              </span>
              [<a href="https://arxiv.org/abs/2006.03204">arxiv</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/eyecar.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1912.07773">EyeCar: Modeling the Visual Attention Allocation of Drivers in Semi-Autonomous Vehicles</a> <br/>
              <span class="pub_authors">Sonia Baee, Erfan Pakdamanian, Vicente Ordonez, Inki Kim, Lu Feng, Laura Barnes. </span>
              <br/><span class="pub_info">arxiv:1912.07773. December 2019.</span>
              [<a href="https://arxiv.org/abs/1912.07773">arxiv</a>]
              </p>
            </div>
          </li>
          
          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/self-paced.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/2001.06001">Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised Learning</a> <br/>
              <span class="pub_authors">Paola Cascante-Bonilla, Fuwen Tan, <a href="https://www.cs.virginia.edu/yanjun/">Yanjun Qi</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>.  </span>
              <br/><span class="pub_info">arxiv:2001.06001. January 2020.</span>
              [<a href="https://arxiv.org/abs/2001.06001">arxiv</a>] 
              [<a href="http://vicenteordonez.com/files/self-paced.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/moviescope.jpeg" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1908.03180">Moviescope: Large-scale Analysis of Movies using Multiple Modalities</a> <br/>
              <span class="pub_authors">Paola Cascante-Bonilla, Kalpathy Sitaraman, Mengjia Luo, <a href="http://vicenteordonez.com">Vicente Ordonez</a>.  </span>
              <br/><span class="pub_info">arXiv:1908.03180. August 2019. 
              [<a href="https://arxiv.org/abs/1908.03180">arxiv</a>] 
              [<a href="http://www.cs.virginia.edu/~pc9za/research/moviescope.html">project page</a>] 
              [<a href="http://vicenteordonez.com/files/moviescope.txt">bibtex</a>]<br/>
              <span style="font-weight:bold;padding-left:20px">
                <a href="https://techxplore.com/news/2019-08-features-movie-genre.html?fbclid=IwAR1oJnZw5WxkcDfaIMOmxZ4Oj9xyuXbkybQhep-aJgcTrRRNwYcooVSGOsA">
                  - TechXplore News Coverage</a>
                </span>
              </p>
            </div>
          </li>


    	</ul>
    </div>


      <h3 class="pb-0 mb-4">
        Publications
      </h3>

      <div class="blog-post subtext p-2">
        <ul class="list-unstyled">

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/double-hard.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
              <span style="color:#e53333">NEW!</span> <a class="blue_link" href="https://arxiv.org/abs/2005.00965">Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation</a> <br/>
              <span class="pub_authors">Tianlu Wang, Xi Victoria Lin, Nazneen Fatema Rajani, Bryan McCann, Vicente Ordonez, Caiming Xiong.</span>
              <span class="pub_info">Association for Computational Linguistics. <strong>ACL 2020</strong>. Seattle, Washington. July 2020.</span>
              [<a href="https://arxiv.org/abs/2005.00965">arxiv</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/openset.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
              <span style="color:#e53333">NEW!</span> <a class="blue_link" href="http://openaccess.thecvf.com/content_CVPR_2020/html/Perera_Generative-Discriminative_Feature_Representations_for_Open-Set_Recognition_CVPR_2020_paper.html"> Generative-discriminative Feature Representations for Open-set Recognition</a> <br/>
              <span class="pub_authors">P. Perera, V. Morariu, R. Jain, V. Manjunatha, C. Wigington, V. Ordonez,  and V. M. Patel.</span>
              <span class="pub_info">Conference on Computer Vision and Pattern Recognition <strong> CVPR 2020</strong>, Seattle, WA.</span>
              [<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Perera_Generative-Discriminative_Feature_Representations_for_Open-Set_Recognition_CVPR_2020_paper.pdf">pdf</a>] [<a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Perera_Generative-Discriminative_Feature_Representations_for_Open-Set_Recognition_CVPR_2020_paper.html">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/testing.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <span style="color:#e53333">NEW!</span> <a class="blue_link" href="https://arxiv.org/abs/1905.07831">Testing DNN Image Classifiers for Confusion &amp; Bias Errors</a> <br/>
              <span class="pub_authors">Yuchi Tian, Ziyuan Zhong, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, Gail Kaiser, <a href="http://rayb.info/">Baishakhi Ray</a>.  </span>
              <br/><span class="pub_info">International Conference on Software Engineering. <strong>ICSE 2020</strong>. Seoul, South Korea, October 2020. 
              [<a href="https://arxiv.org/abs/1905.07831">arxiv</a>] [<a href="http://vicenteordonez.com/files/testing_bib.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/drilldown.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1911.03826">Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries</a> <br/>
              <span class="pub_authors">Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, <a href="https://www.spacewu.com/">Hui Wu</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng">Song Feng</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>.  </span>
              <span class="pub_info">Conf. on Neural Information Processing Systems. <strong>NeurIPS 2019</strong>. Vancouver, Canada. December 2019. 
              [<a href="https://arxiv.org/abs/1911.03826">arxiv</a>] [<a href="https://github.com/uvavision/DrillDown">code</a>] [<a href="http://vicenteordonez.com/files/drilldown.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/debias.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1811.08489">Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</a>. 
              <span class="pub_authors">Tianlu Wang, Jieyu Zhao, <a href="http://markyatskar.com/">Mark Yatskar</a>, <a href="http://www.cs.virginia.edu/~kc2wc/">Kai-Wei Chang</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>.  </span>
              <span class="pub_info">International Conference on Computer Vision. <strong>ICCV 2019</strong>. Seoul, South Korea. October 2019. 
              [<a href="https://arxiv.org/abs/1811.08489">arxiv</a>] 
              [<a href="https://github.com/uvavision/Balanced-Datasets-Are-Not-Enough">code</a>] 
              [<a href="https://www.vislang.ai/genderless">demo</a>] 
              [<a href="http://vicenteordonez.com/files/gendervision.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/text2scene.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
                <a class="blue_link" href="https://arxiv.org/abs/1809.01110">Text2Scene: Generating Compositional Scenes from Textual Descriptions</a> <br/>
                <span class="pub_authors">Fuwen Tan, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng">Song Feng</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a></span>. <span class="pub_info">Intl. Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2019</strong>. Long Beach, California. June 2019.</span> 
                [<a href="https://arxiv.org/abs/1809.01110">arxiv</a>] 
                [<a href="https://github.com/uvavision/Text2Scene">code</a>] 
                [<a href="https://www.vislang.ai/text2scene">demo</a>] 
                [<a href="http://vicenteordonez.com/files/text2scene_bib.txt">bibtex</a>]
                <br/> <em style="color:#a00">(~Oral presentation + Best Paper Finalist <span style="font-size:0.8em;font-weight:lighter;"> -- top 1% of submissions</span>)</em><br/>
                <span style="font-weight:bold;padding-left:20px"><a href="https://www.ibm.com/blogs/research/2019/06/text2scene-textual-descriptions/">- IBM Research Blog Coverage</a></span><br/>
                <span style="font-weight:bold;padding-left:20px"><a href="https://news.developer.nvidia.com/ai-model-can-generate-images-from-natural-language-descriptions/">- NVIDIA News Coverage</a>
                </p>
            </div>
          </li>

           <li class="media">
            <img class="mr-3 img-thumbnail" src="images/bias-nlp.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
               <a class="blue_link" href="#">Gender Bias in Contextualized Word Embeddings</a> <br/>
              <span class="pub_authors">Jieyu Zhao, Tianlu Wang, <a href="http://markyatskar.com/">Mark Yatskar</a>, <a href="https://ryancotterell.github.io/">Ryan Cotterell</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, <a href="http://www.cs.virginia.edu/~kc2wc/">Kai-Wei Chang</a>.  </span>
              <span class="pub_info">North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2019</strong>. short. Minneapolis, Minnesota. June 2019.</span> 
              [<a href="https://arxiv.org/abs/1904.03310">arxiv</a>] 
              [<a href="http://vicenteordonez.com/files/genderbiaselmo_bib.txt">bibtex</a>]<br/> <em style="color:#a00">(~Oral presentation)</em>
              </p>
            </div>
          </li>

           <li class="media">
            <img class="mr-3 img-thumbnail" src="images/chatcrowd3.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
               <a class="blue_link" href="https://chatcrowd.github.io/">Chat-crowd: A Dialog-based Platform for Visual Layout Composition</a> <br/>
              <span class="pub_authors">Paola Cascante-Bonilla, Xuwang Yin, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng">Song Feng</a>.  </span>
              <span class="pub_info">North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2019</strong>. System Demonstrations. Minneapolis, Minnesota. June 2019.</span>
              [<a href="https://arxiv.org/abs/1812.04081">arxiv</a>] 
              [<a href="https://chatcrowd.github.io/">project page</a>] 
              [<a href="https://github.com/uvavision/chat-crowd">code</a>]
              </p>
            </div>
          </li>


           <li class="media">
            <img class="mr-3 img-thumbnail" src="images/multimedia.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1805.08587">Deep Feature Aggregation and Image Re-ranking with Heat Diffusion for Image Retrieval</a>.
              <span class="pub_authors">Shanmin Pang, Jin Ma, Jianru Xue, Jihua Zhu, Vicente Ordonez.  </span>
              <br/><span class="pub_info"><strong>IEEE Transactions on Multimedia 2019</strong> (Journal). [Accepted October 2018].</span><br/>
              [<a href="https://arxiv.org/abs/1805.08587">arxiv</a>] 
              [<a href="http://vicenteordonez.com/files/multimedia.txt">bibtex</a>]
              </p>
            </div>
          </li>

           <li class="media">
            <img class="mr-3 img-thumbnail" src="images/feedbackprop.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1710.08049">Feedback-prop: Convolutional Neural Network Inference under Partial Evidence</a> <br/>
              <span class="pub_authors"><a href="http://www.cs.virginia.edu/~tw8cb/">Tianlu Wang</a>, <a href="http://vision.is.tohoku.ac.jp/~kyamagu/">Kota Yamaguchi</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a></span>. <span class="pub_info">Intl. Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2018</strong>. Salt Lake City, Utah. June 2018.</span> 
              [<a href="https://arxiv.org/pdf/1710.08049.pdf">pdf</a>] 
              [<a href="https://arxiv.org/abs/1710.08049">arXiv</a>] 
              [<a href="https://github.com/uvavision/feedbackprop">code</a>] 
              [<a href="http://vicenteordonez.com/files/feedbackprop_bib.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/bias-nlp.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1804.06876">Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods</a> <br/>
              <span class="pub_authors">Jieyu Zhao, Tianlu Wang, <a href="http://markyatskar.com/">Mark Yatskar</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, <a href="http://www.cs.virginia.edu/~kc2wc/">Kai-Wei Chang</a>.  </span>
              <br/><span class="pub_info">North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2018</strong>. short. New Orleans, Louisiana. June 2018.</span>
              [<a href="http://vicenteordonez.com/files/winobias.pdf">pdf</a>] 
              [<a href="https://arxiv.org/abs/1804.06876">arXiv</a>] 
              [<a href="https://github.com/uclanlp/corefBias">code</a>] 
              [<a href="http://vicenteordonez.com/files/coref_bias.txt">bibtex</a>] 
              </p>
            </div>
          </li>

           <li class="media">
            <img class="mr-3 img-thumbnail" src="images/pr2018.png" width="100" alt="">
            <div class="media-body">
            <p class="my-auto">
              <a class="blue_link" href="https://www.sciencedirect.com/science/article/pii/S0031320318301808">
                Building Discriminative CNN Image Representations for Object Retrieval using the Replicator Equation
              </a>.
              <span class="pub_authors">Shanmin Pang, Jihua Zhu, Jiaxing Wang, Vicente Ordonez, Jianru Xue.  </span>
              <span class="pub_info"><strong>Pattern Recognition 2018</strong> (Journal). Volume 83. Pages 150-160. [Accepted April 2018].</span> 
              [<a href="https://www.sciencedirect.com/science/article/pii/S0031320318301808">link</a>] 
              [<a href="https://github.com/pangsm0415/ReSW">code</a>] 
              [<a href="http://vicenteordonez.com/files/pr2018.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/composition.png" width="100" alt="">
            <div class="media-body">
            <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1706.01021">Where and Who? Automatic Semantic-Aware Person Composition</a> <br/>
              <span class="pub_authors">Fuwen Tan, Crispin Bernier, Benjamin Cohen, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, Connelly Barnes.  </span>
              <br/><span class="pub_info">Winter Conference on Applications of Computer Vision. <strong>WACV 2018</strong>. Lake Tahoe, Nevada. March 2018.</span>
              [<a href="http://vicenteordonez.com/files/wacv18.pdf">pdf</a>] 
              [<a href="https://arxiv.org/abs/1706.01021">arXiv</a>] 
              [<a href="http://vicenteordonez.com/files/wacv18_supp.pdf">supp. material</a>] 
              [<a href="https://github.com/fwtan/who_where">code</a>] 
              [<a href="http://vicenteordonez.com/files/TanBCOB17.txt">bibtex</a>]
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/bias.png" width="100" alt="">
            <div class="media-body">
            <p class="my-auto">
              <a class="blue_link" href="http://vicenteordonez.com/files/bias.pdf">Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints</a>. 
              <span class="pub_authors">Jieyu Zhao, Tianlu Wang, <a href="http://markyatskar.com/">Mark Yatskar</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, <a href="http://www.cs.virginia.edu/~kc2wc/">Kai-Wei Chang</a>.  </span>
              <br/><span class="pub_info">Empirical Methods in Natural Language Processing. <strong>EMNLP 2017</strong>. Copenhagen, Denmark. September 2017.</span>
              [<a href="http://vicenteordonez.com/files/bias.pdf">pdf</a>] 
              [<a href="https://github.com/uclanlp/reducingbias">code</a>] 
              [<a href="http://vicenteordonez.com/files/biasemnlp.txt">bibtex</a>]
              <br/><em style="color:#a00">(~Oral presentation + Best Long Paper Award!)</em><br/>
              <span style="font-weight:bold;padding-left:20px"><a href="https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/">- WIRED News Coverage</a></span><br/>
              <span style="font-weight:bold;padding-left:20px"><a href="http://www.dailymail.co.uk/sciencetech/article-4810982/AIs-learn-photos-sexist.html">- Daily Mail News Coverage</a></span><br/>
              <span style="font-weight:bold;padding-left:20px"><a href="https://www.thetimes.co.uk/article/home-robots-will-turn-into-crude-sexists-experts-warn-gnmj09rgq">- Times of London News Coverage</a></span>
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/obj2text.png" width="100" alt="">
            <div class="media-body">
            <p class="my-auto">
              <a class="blue_link" href="http://vision.cs.virginia.edu/obj2text">Obj2Text: Generating Visually Descriptive Language from Object Layouts</a> <br/>
              <span class="pub_authors">Xuwang Yin, <a href="http://vicenteordonez.com">Vicente Ordonez</a>.  </span>
              <span class="pub_info">Empirical Methods in Natural Language Processing. <strong>EMNLP 2017</strong>. Copenhagen, Denmark. September 2017.</span>
              [<a href="http://vicenteordonez.com/files/obj2text.pdf">pdf</a>] 
              [<a href="https://arxiv.org/abs/1707.07102">arxiv</a>] 
              [<a href="https://github.com/uvavision/obj2text-neuraltalk2">code</a>] 
              [<a href="http://vicenteordonez.com/files/obj2text.txt">bibtex</a>]
              <em style="color:#a00">(~Oral presentation)</em>
              </p>
            </div>
          </li>

           <li class="media">
            <img class="mr-3 img-thumbnail" src="images/imsitu.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
              <a class="blue_link" href="https://arxiv.org/abs/1612.00901">Commonly Uncommon: Semantic Sparsity in Situation Recognition</a> <br/>
              <span class="pub_authors"><a href="http://markyatskar.com/">Mark Yatskar</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, <a href="https://www.cs.washington.edu/people/faculty/lsz">Luke Zettlemoyer</a>, <a href="https://homes.cs.washington.edu/~ali/">Ali Farhadi</a></span>.  
              <br/><span class="pub_info">Intl. Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2017</strong>. Honolulu, Hawaii. July 2017.</span>
              [<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yatskar_Commonly_Uncommon_Semantic_CVPR_2017_paper.pdf">pdf</a>] 
              [<a href="https://arxiv.org/abs/1612.00901">arXiv</a>] 
              [<a href="http://vicenteordonez.com/files/commonly_uncommon_bib.txt">bibtex</a>] 
              [<a href="http://imsitu.org/demo">demo</a>] 
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/xnornet.png" width="100" alt="">
            <div class="media-body">
            <p class="my-auto">
              <a class="blue_link" href="http://arxiv.org/abs/1603.05279">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a> <br/>
              <span class="pub_authors"><a href="http://www.umiacs.umd.edu/~mrastega/">Mohammad Rastegari</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>, <a href="http://pjreddie.com/">Joseph Redmon</a>, <a href="https://homes.cs.washington.edu/~ali/">Ali Farhadi</a></span>. 
              <br/><span class="pub_info">European Conference on Computer Vision. <strong>ECCV 2016</strong>. Amsterdam, The Netherlands. October 2016.</span>
              [<a href="http://arxiv.org/abs/1603.05279">arXiv</a>] 
              [<a href="http://allenai.org/plato/xnornet/">project page</a>] 
              [<a href="https://github.com/allenai/XNOR-Net">code</a>] 
              [<a href="http://vicenteordonez.com/files/xnornet_bib.txt">bibtex</a>]
              <em style="color:#a00">(~Oral presentation)</em><br/>
              <span style="font-weight:bold;padding-left:20px"><a href="http://www.nytimes.com/2016/10/31/technology/beyond-silicon-squeezing-more-out-of-chips.html">- New York Times News Coverage</a></span><br/>
              <span style="font-weight:bold;padding-left:20px"><a href="https://news.cs.washington.edu/2016/10/31/uw-cse-and-ai2-in-the-new-york-times-artificial-intelligence-at-your-fingertips/">- Article on University of Washington News</a></span>
              </p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/commonsense.png" width="100" alt="">
            <div class="media-body">
             <p class="my-auto">
              <a class="blue_link" href="http://vicenteordonez.com/files/naacl2016.pdf">Stating the Obvious: Extracting Visual Common Sense Knowledge</a> <br/>
              <span class="pub_authors"><a href="http://markyatskar.com/">Mark Yatskar</a>, <a href="http://vicenteordonez.com">Vicente Ordonez</a>,  <a href="https://homes.cs.washington.edu/~ali/">Ali Farhadi</a></span>. 
              <span class="pub_info"> North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2016</strong>. short. San Diego, CA. June 2016.</span>
              [<a href="http://vicenteordonez.com/files/naacl2016.pdf">pdf</a>] 
              [<a href="http://vicenteordonez.com/files/naacl2016_bib.txt">bibtex</a>]
              <em style="color:#a00">(~Oral presentation)</em>
              </p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/cacm.png" width="100" alt="">
            <div class="media-body">
              <p class="my-auto">
                 <a class="blue_link" href="http://vicenteordonez.com/files/cacm2016.pdf">Learning to Name Objects</a> <br/>
                <span class="pub_authors"><a href="http://vicenteordonez.com">Vicente Ordonez</a>, Wei Liu, <a href="http://web.eecs.umich.edu/~jiadeng/">Jia Deng</a>, <a href="http://homes.cs.washington.edu/~yejin/">Yejin Choi</a>, <a href="http://acberg.com">Alexander C. Berg</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>. 
                <br/><span class="pub_info"> <strong>Communications of the ACM</strong>. March 2016 (Vol. 59, No. 3).</span> <em style="color:#a00">(~Research Highlight)</em>
                <br/>
                [<a href="http://vicenteordonez.com/files/cacm2016.pdf">pdf</a>] 
                [<a href="http://cacm.acm.org/magazines/2016/3/198851-learning-to-name-objects/fulltext">link</a>] 
                [<a href="http://cacm.acm.org/magazines/2016/3/198875-technical-perspective-taming-the-name-game/fulltext">technical perspective</a>] 
                [<a href="http://vicenteordonez.com/files/cacm_bib.txt">bibtex</a>]
                </p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/whatshouldicallit.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="files/ijcv_entrylevel.pdf">Predicting Entry-Level Categories</a> <br/>
				<span class="pub_authors"><a href="index.html">Vicente Ordonez</a>, Wei Liu, <a href="http://web.eecs.umich.edu/~jiadeng/">Jia Deng</a>, <a href="http://homes.cs.washington.edu/~yejin/">Yejin Choi</a>, <a href="http://acberg.com">Alexander C. Berg</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>. 
				<br/><span class="pub_info"> International Journal of Computer Vision - Marr Prize Special Issue. <strong>IJCV 2015</strong>.</span>
        <br/>
        [<a href="files/ijcv_entrylevel.pdf">pdf</a>] 
        [<a href="http://link.springer.com/article/10.1007/s11263-015-0815-z">link</a>]
				[<a href="files/ijcv_entrylevel_bib.txt">bibtex</a>]
			  </p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/generation.png" width="100" alt="">
            <div class="media-body">
            <p>
				<a class="blue_link" href="files/ijcv_bigdata.pdf">Large Scale Retrieval and Generation of Image Descriptions</a><br/>
				<span class="pub_authors"><a href="index.html">V. Ordonez</a>, X. Han, P. Kuznetsova, G. Kulkarni, M. Mitchell, K. Yamaguchi, K. Stratos, <br/>A. Goyal, J. Dodge, A. Mensch, H. Daume III, A.C. Berg, Y. Choi, T.L. Berg</span>. 
				<br/><span class="pub_info"> International Journal of Computer Vision. <strong>IJCV 2015</strong>. [August 2016 Issue].</span>
        [<a href="files/ijcv_bigdata.pdf">pdf</a>] 
        [<a href="http://dx.doi.org/10.1007/s11263-015-0840-y">link</a>]
				[<a href="files/ijcv_bigdata_bib.txt">bibtex</a>]
			</p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3" src="images/unc_seal_blue.jpg" width="80" alt="">
            <div class="media-body ml-4">
             <p>
				Ph.D. Thesis. [<a href="files/thesis_4-24-2015.pdf">pdf</a>] [<a href="files/thesis_4-24-2015_bib.txt">bibtex</a>]
				<br/> Language and Perceptual Categorization in Computational Visual Recognition.<br/>
				<span class="pub_authors"><a href="index.html">Vicente Ord&oacute;&ntilde;ez Rom&aacute;n</a>. April 2015.</span>
				<br/>Department of Computer Science. The University of North Carolina at Chapel Hill. </span>
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/referitgame.png" width="100" alt="">
            <div class="media-body">
            <p>
				<a class="blue_link" href="http://tamaraberg.com/referitgame/">ReferItGame: Referring to Objects in Photographs of Natural Scenes</a><br/>
				<span class="pub_authors">Sahar Kazemzadeh, <a href="index.html">Vicente Ordonez</a>, Mark Matten, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>. 
				<br/><span class="pub_info"> Empirical Methods on Natural Language Processing. <strong>EMNLP 2014</strong>. Doha, Qatar. October 2014.</span>
        [<a href="files/referit.pdf">pdf</a>] 
        [<a href="http://www.cs.virginia.edu/~vicente/referit/">project page</a>] 
        [<a href="http://referitgame.com">game</a>]
				[<a href="files/referit_bib.txt">bibtex</a>] 
				<em style="color:#a00">(~Oral presentation)</em>
			</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/urban.png" width="100" alt="">
            <div class="media-body">
              <p>
				<a class="blue_link" href="http://www.cs.virginia.edu/~vicente/urban/index.html">Learning High-level Judgments of Urban Perception</a><br/>
				<span class="pub_authors"><a href="index.html">Vicente Ordonez</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>. 
				<br/><span class="pub_info"> European Conference on Computer Vision. <strong>ECCV 2014</strong>. Zurich, Switzerland. September 2014.</span>
        [<a href="urban/vicente_eccv14.pdf">pdf</a>]
        [<a href="http://www.cs.virginia.edu/~vicente/urban/index.html">project page</a>]
				[<a href="files/vicente_eccv14_bib.txt">bibtex</a>]
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/treetalk.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="files/treetalk_camera_ready.pdf">TreeTalk: Composition and Compression of Trees for Image Descriptions</a><br/>
				<span class="pub_authors"><a href="http://www.cs.stonybrook.edu/~pkuznetsova">Polina Kuznetsova, <a href="index.html">Vicente Ordonez</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a>, <a href="http://homes.cs.washington.edu/~yejin/">Yejin Choi</a></span>. 
        <br/><span class="pub_info"> Transactions of the Association for Computational Linguistics. <strong>TACL 2014</strong>. <br/>To be presented at EMNLP 2014 in Doha, Qatar. October 2014.</span> 
        [<a href="files/treetalk_camera_ready.pdf">pdf</a>]
				[<a href="files/treetalk_camera_ready_bib.txt">bibtex</a>]
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/furniture2.png" width="100" alt="">
            <div class="media-body">
              <p>
				<span style="color:#e53333;font-family:Helvetica"></span> <a class="blue_link" href="files/furnituregeek.pdf">Furniture-Geek: Understanding Fine-Grained Furniture Attributes
				from Freely Associated Text and Tags</a><br/>
				<span class="pub_authors"><a href="index.html">Vicente Ordonez, <a href="http://labs.ebay.com/people/vignesh-jagadeesh/">Vignesh Jagadeesh</a>, <a href="#">Wei Di</a>, <a href="#">Anurag Bhardwaj</a>, <a href="http://labs.ebay.com/people/robinson-piramuthu/">Robinson Piramuthu</a></span>. 
				<span class="pub_info">IEEE Winter Conference on Applications of Computer Vision. <strong>WACV 2014</strong>. Steamboat Springs, CO. March 2014.</span>
        [<a href="files/furnituregeek.pdf">pdf</a>] 
        [<a href="files/furnituregeek_bib.txt">bibtex</a>]
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/whatshouldicallit.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="http://www.cs.virginia.edu/~vicente/entrylevel/index.html">From Large Scale Image Categorization to Entry-Level Categories</a> <br/>
				<span class="pub_authors"><a href="index.html">Vicente Ordonez</a>, <a href="http://ai.stanford.edu/~jiadeng/">Jia Deng</a>, <a href="http://homes.cs.washington.edu/~yejin/">Yejin Choi</a>, <a href="http://acberg.com">Alexander C. Berg</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>. 
				<br/><span class="pub_info">IEEE International Conference on Computer Vision. <strong>ICCV 2013</strong>. Sydney, Australia. December 2013.</span>
        [<a href="files/entrylevel.pdf">pdf</a>] 
        [<a href="files/entrylevel_supplemental.pdf">supplemental material</a>] 
        [<a href="entrylevel/iccv2013_slides.pptx">slides</a>] 
        [<a href="http://www.cs.virginia.edu/~vicente/entrylevel/index.html">project page</a>] 
        [<a href="files/entrylevel_bib.txt">bibtex</a>] <em style="color:#a00">(~Oral Presentation + Best Paper Award - Marr Prize!)</em>
				</p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/generalizing.png" width="100" alt="">
            <div class="media-body">
              <p>
				<a class="blue_link" href="files/acl13_generalization.pdf">Generalizing Image Captions for Image-Text Parallel Corpus</a><br/>
				<span class="pub_authors"><a href="http://www.cs.stonybrook.edu/~pkuznetsova">Polina Kuznetsova, <a href="index.html">Vicente Ordonez</a>, <a href="http://acberg.com">Alexander C. Berg</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a>, <a href="http://homes.cs.washington.edu/~yejin/">Yejin Choi</a></span>. 
				<br/><span class="pub_info">Association for Computational Linguistics. <strong>ACL 2013</strong>. short. Sofia, Bulgaria. August 2013.</span>
        [<a href="files/acl13_generalization.pdf">pdf</a>] 
        [<a href="http://www.cs.stonybrook.edu/~pkuznetsova/imgcaption/">data+results</a>]
				[<a href="files/acl13_generalization_bib.txt">bibtex</a>]
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/babytalk2.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="files/babytalk_pami13.pdf">Baby Talk: Understanding and Generating Simple Image Descriptions</a><br/>
				<span class="pub_authors">G. Kulkarni, V. Premraj, <a href="index.html">V. Ordonez</a>, S. Dhar, S. Li, <a href="http://homes.cs.washington.edu/~yejin/">Y. Choi</a>, <a href="http://acberg.com">A. C. Berg</a>, <a href="http://tamaraberg.com">T. L. Berg</a></span>. 
				<br/><span class="pub_info"> IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong>PAMI 2013</strong></span>
        <br/>
        [<a href="files/babytalk_pami13.pdf">pdf</a>] 
        [<a href="http://dx.doi.org/10.1109/TPAMI.2012.162">link</a>] 
				[<a href="files/babytalk_pami13_bib.txt">bibtex</a>]
				</p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/acl.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="files/acl12_generation.pdf">Collective Generation of Natural Image Descriptions</a><br/>
				<span class="pub_authors"><a href="http://www.cs.stonybrook.edu/~pkuznetsova">Polina Kuznetsova, <a href="index.html">Vicente Ordonez</a>, <a href="http://acberg.com">Alexander C. Berg</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a>, <a href="http://homes.cs.washington.edu/~yejin/">Yejin Choi</a></span>. 
				<br/><span class="pub_info"> Association for Computational Linguistics. <strong>ACL 2012</strong>. Jeju, South Korea. July 2012.</span>
        <br/>
        [<a href="files/acl12_generation.pdf">pdf</a>] 
        [<a href="http://tlberg.cs.unc.edu/~vicente/clsp11/SBU_Captioned_Photo_Dataset_v1.1.tgz">data</a>]
				[<a href="files/acl12_generation_bib.txt">bibtex</a>]
				<em style="color:#a00">(~Oral presentation)</em>
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/im2text.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="http://www.cs.virginia.edu/~vicente/sbucaptions">Im2Text: Describing Images Using 1 Million Captioned Photographs</a><br/>
				<span class="pub_authors"><a href="index.html">Vicente Ordonez</a>, Girish Kulkarni, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>.
				<br/><span class="pub_info">Conf. in Neural Information Processing Systems. <strong>NeurIPS 2011</strong>. Granada, Spain. December 2011.</span>
        [<a href="files/generation_nips2011.pdf">pdf</a>] 
        [<a href="http://www.cs.virginia.edu/~vicente/sbucaptions/">code+dataset</a>] 
        [<a href="files/im2text_nips11_poster.pdf">poster</a>]  
        <!--[<a href="http://tlberg.cs.unc.edu/vicente/python_server_files/py/website/search.py">search tool</a>]--> 
        [<a href="https://www.vislang.ai/sbu-explore">search tool</a>]
        [<a href="files/generation_nips2011_bib.txt">bibtex</a>]
				<em style="color:#a00">(~Spotlight presentation)</em>
				</p>
            </div>
          </li>

          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/aesthetics.png" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="files/aesthetics_cvpr11.pdf">High Level Describable Attributes for Predicting Aesthetics and Interestingness</a><br/>
				<span class="pub_authors">Sagnik Dhar, <a href="index.html">Vicente Ordonez</a>, <a href="http://tamaraberg.com">Tamara L. Berg</a></span>. 
				<br/><span class="pub_info">IEEE Computer Vision and Pattern Recognition. <strong>CVPR 2011</strong>. Colorado Springs, CO. June 2011.</span> 
        [<a href="files/aesthetics_cvpr11.pdf">pdf</a>] 
        [<a href="code.html">related code for saliency + low DoF attributes</a>]
				[<a href="files/aesthetics_cvpr11_bib.txt">bibtex</a>] 
				</p>
            </div>
          </li>


          <li class="media">
            <img class="mr-3 img-thumbnail" src="images/ariadne.jpg" width="100" alt="">
            <div class="media-body">
             <p>
				<a class="blue_link" href="http://dx.doi.org/10.1109/MIC.2009.90">The Ariadne Infrastructure for Managing and Storing Metadata</a><br/>
				<span class="pub_authors">S. Ternier, G. Parra, B. Vandeputte, K. Verbert, J. Klerkx, <a href="http://www.cs.kuleuven.ac.be/~erikd/">E. Duval</a>, <a href="index.html">V. Ordonez</a>, <a href="http://ariadne.cti.espol.edu.ec/xavier">X. Ochoa</a></span>. 
				<span class="pub_info"><strong>IEEE Internet Computing 2009 </strong>. Emerging Internet Technologies and Applications for E-learning.</span> 
				[<a href="http://dx.doi.org/10.1109/MIC.2009.90">link</a>]
				</p>
            </div>
          </li>


        </ul>
        
      </div><!-- /.blog-post -->

    </div><!-- /.website-main -->

	   <aside class="col-md-4 page-sidebar m-0 py-0">
      <div class="px-1 mb-4">
        <h3>Group Members</h3>
        <ul class="list-unstyled pl-3 pt-2">
       	<li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/tianlu.jpg" width="56" alt="">
    				<div class="media-body">
    				  <a href="http://www.cs.virginia.edu/~tw8cb/">Tianlu Wang</a>
    				  <p>PhD Student</p>
    				</div>
       	</li>
       	<li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/paola.jpg" width="56" alt="">
    				<div class="media-body">
    				  <a href="https://paolacascante.com/">Paola Cascante-Bonilla</a>
    				  <p>PhD Student</p>
    				</div>
       	</li>
       	<li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/fuwen.jpg" width="56" alt="">
    				<div class="media-body">
    				  <a href="http://www.cs.virginia.edu/~ft3ex/">Fuwen Tan</a>
    				  <p>PhD Student</p>
    				</div>
       	</li>
       	<li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/ziyan.jpg" width="56" alt="">
    				<div class="media-body">
    				  Ziyan Yang
    				  <p>PhD Student</p>
    				</div>
       	</li>
       	<li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/jeffrey.jpg" width="56" alt="">
    				<div class="media-body">
    				  Jeffrey Tan
    				  <p>Undergraduate Student</p>
    				</div>
       	</li>
       	<li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/lindsey.jpg" width="56" alt="">
    				<div class="media-body">
    				  Lindsey Shavers
    				  <p>Undergraduate Student</p>
    				</div>
       	</li>
     	  <li class="media mb-1"><img class="mr-2 img-thumbnail p-0" src="images/leticia.jpg" width="56" alt="">
  				<div class="media-body">
    				  Leticia Pinto-Alva
    				  <p>Visiting Student</p>
    				</div>
       	</li>
        </ul>
      </div>
      </div>
    </aside><!-- /.page-sidebar -->

  </div><!-- /.row -->

<div class="row mx-0 mx-lg-2 container justify-content-center">
	<div class="col-12 text-muted text-center text-smallest">CURRENT AND PAST SPONSORS</div>
	<div class="col-10 m-0 d-flex flex-column flex-md-row p-0">
		<img src="images/sap-logo.svg" height="30" alt="SAP SE" class="mx-auto my-3"/>
		<img src="images/facebook-logo.jpg" height="50" alt="Facebook AI" class="mx-auto my-1"/>
		<img src="images/leidos-logo.svg" height="28" alt="Leidos Inc" class="mx-auto my-3"/>
		<img src="images/ebay-logo.png" height="55" alt="eBay Inc" class="mx-auto my-1"/>
		<img src="images/adobe.svg" height="45" alt="Adobe" class="mx-auto my-2"/>
		<img src="images/ibm-logo.png" height="27" alt="IBM Research" class="mx-auto my-3"/>
		<img src="images/google-logo.svg" height="36" alt="Google" class="mx-auto my-3"/>
	</div>
</div>

</main><!-- /.container -->

<footer class="page-footer">
  <p>Department of Computer Science @ <a href="http://www.virginia.edu">the University of Virginia</a> ‒ 85 Engineer's Way, Rice Hall, Charlottesville, VA 22904-4740
  </p>
</footer>

<!-- Optional JavaScript -->
<!-- jQuery first, then Bootstrap JS -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="js/bootstrap.min.js"></script>

</body>
</html>
